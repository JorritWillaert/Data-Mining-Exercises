{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending movies using collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:48.346620Z",
     "start_time": "2020-03-24T19:41:47.795318Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a recommender system, we need data to learn from. Specifically, we need the a dataset of **ratings** that different **users** assigend to different **items**, i.e., the movies. Let's start by loading the data and look at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:41:49.210677Z",
     "start_time": "2020-03-24T19:41:49.138507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest user id:  943\n",
      "Lowest user id:  1\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "    '../datasets/u.data',\n",
    "    delimiter='\\t',\n",
    "    header=None,\n",
    "    names=['user_id', 'item_id', 'rating', 'timestamp']\n",
    ") \n",
    "\n",
    "# We don't need the column timestamp, so we drop it\n",
    "ratings.drop('timestamp', axis=1 , inplace=True)\n",
    "\n",
    "ratings.head()\n",
    "lowest_user_id = ratings['user_id'].min()\n",
    "highest_user_id = ratings['user_id'].max()\n",
    "print(\"Highest user id: \", highest_user_id)\n",
    "print(\"Lowest user id: \", lowest_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Similarity-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Implement the similarity-based algorithm given by the formulas of exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_rating(df, user):\n",
    "    user_rows = df.loc[df['user_id'] == user]\n",
    "    avg_rating = user_rows['rating'].mean()\n",
    "    return avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(df, user_i, user_j):\n",
    "    avg_i = calculate_avg_rating(df, user_i)\n",
    "    avg_j = calculate_avg_rating(df, user_j)\n",
    "    rows_i = df.loc[df['user_id'] == user_i]\n",
    "    rows_j = df.loc[df['user_id'] == user_j]\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for _, row_i in rows_i.iterrows():\n",
    "        for _, row_j in rows_j.iterrows():\n",
    "            if row_i['item_id'] == int(row_j['item_id']):\n",
    "                numerator += (row_i['rating'] - avg_i) * (row_j['rating'] - avg_j)\n",
    "                denominator += ((row_i['rating'] - avg_i) ** 2) + ((row_j['rating'] - avg_j) ** 2)\n",
    "    numerator /= 2. # Will have counted twice\n",
    "    denominator = denominator ** (1/2)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Let's now use the similarity function to find similar users. Given a user `u`, find the\n",
    "- user that is the most similar (positively correlated) to `u`;\n",
    "- user that is the least similar (negatively correlated) to `u`;\n",
    "- user that is weakly correlated to `u`.\n",
    "\n",
    "What can you say about the influence that these three users will have on the ratings of user `u`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pos_cor = float('-inf')\n",
    "neg_cor = float('+inf')\n",
    "user_i_neg, user_j_neg, user_i_pos, user_j_pos = -1, -1, -1, -1\n",
    "for i in range(lowest_user_id, highest_user_id - 1):\n",
    "    for j in range(i + 1, highest_user_id):\n",
    "        cor = calculate_similarity(ratings, i, j)\n",
    "        if cor < neg_cor:\n",
    "            neg_cor = cor\n",
    "            user_i_neg = i\n",
    "            user_j_neg = j\n",
    "        if cor > pos_cor:\n",
    "            pos_cor = cor\n",
    "            user_i_pos = i\n",
    "            user_j_pos = j\n",
    "\n",
    "print('User positively correlated: user', user_i_pos, ' and ', user_j_pos, 'with similarity =', pos_cor)\n",
    "print('User negatively correlated: user', user_i_neg, ' and ', user_j_neg, 'with similarity =', pos_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:25:28.779063Z",
     "start_time": "2020-03-24T20:25:28.774304Z"
    }
   },
   "source": [
    "**Question 3:** Use your implementation to predict an unknown rating of the dataset. What is the run time of your implementation? Can you think of ways to speed it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T19:54:12.638063Z",
     "start_time": "2020-03-24T19:54:11.923327Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our life easier, we will now use the [Surprise](https://surprise.readthedocs.io) Python package which implements a variety of collaborative filtering algorithms. To install this package, simply run `pip install surprise` or use conda if you use Windows: open anaconda navigator, go to environments, click on the arrow next to the base (root) environment, click \"open terminal\" and run the following command: `conda install -y -c conda-forge scikit-surprise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:17:40.110191Z",
     "start_time": "2020-03-24T20:17:39.972036Z"
    }
   },
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to convert our dataset to a format where the rows represent users and the columns represent the movies. The value at each cell is the rating for corresponding user and movie, or zero if the user did not rate the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:22:34.526564Z",
     "start_time": "2020-03-24T20:22:34.295657Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise.dataset import Dataset, Reader\n",
    "dataset = Dataset.load_from_df(ratings, reader=Reader(rating_scale=(1, 5)))\n",
    "X = dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Now use the non-negative matrix factorization implementation of this package to predict the rating for a given user and movie.\n",
    "\n",
    "Hint: you'll need the [surprise.prediction_algorithms.matrix_factorization.NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:29:03.084232Z",
     "start_time": "2020-03-24T20:28:55.536552Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What is the effect of the number of latent factors? Is there an optimal number of factors?\n",
    "\n",
    "Hint: the [surprise.model_selection.search.GridSearchCV](https://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.search.GridSearchCV) makes it easy to compare different parameter settings (note that GridSearchCV.fit expects a Dataset object instead of a Trainset object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T21:05:52.161305Z",
     "start_time": "2020-03-24T21:05:51.790956Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
